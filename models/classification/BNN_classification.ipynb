{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bitcoin price prediction with Bayesian Neural Network Classification using torchBNN and PyTorch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "import torchbnn as bnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "from os.path import dirname, abspath\n",
    "while not cwd.endswith('BT4222_repo'):\n",
    "    cwd = os.path.dirname(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Adj_Close_BTC-USD</th>\n",
       "      <th>Open_BTC-USD</th>\n",
       "      <th>High_BTC-USD</th>\n",
       "      <th>Low_BTC-USD</th>\n",
       "      <th>Volume_BTC-USD</th>\n",
       "      <th>Adj_Close_SPY</th>\n",
       "      <th>Adj_Close_GLD</th>\n",
       "      <th>Adj_Close_CHFUSD=X</th>\n",
       "      <th>Adj_Close_CNYUSD=X</th>\n",
       "      <th>Adj_Close_EURUSD=X</th>\n",
       "      <th>Adj_Close_GBPUSD=X</th>\n",
       "      <th>Adj_Close_JPYUSD=X</th>\n",
       "      <th>coindesk_sentiment</th>\n",
       "      <th>num_of_coindesk_posts</th>\n",
       "      <th>reddit_comments_sentiments</th>\n",
       "      <th>top_50_reddit_posts_sentiments</th>\n",
       "      <th>blockchain_transactions_per_block</th>\n",
       "      <th>blockchain_hash_rates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>19246.6445</td>\n",
       "      <td>19144.4922</td>\n",
       "      <td>19305.0996</td>\n",
       "      <td>19012.7090</td>\n",
       "      <td>2.250000e+10</td>\n",
       "      <td>361.926788</td>\n",
       "      <td>171.539993</td>\n",
       "      <td>1.125442</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>1.213340</td>\n",
       "      <td>1.331824</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.249489</td>\n",
       "      <td>12</td>\n",
       "      <td>0.158060</td>\n",
       "      <td>0.677618</td>\n",
       "      <td>2167.93103</td>\n",
       "      <td>134533588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>19417.0762</td>\n",
       "      <td>19246.9199</td>\n",
       "      <td>19525.0078</td>\n",
       "      <td>19079.8418</td>\n",
       "      <td>2.670000e+10</td>\n",
       "      <td>366.819824</td>\n",
       "      <td>173.940002</td>\n",
       "      <td>1.127930</td>\n",
       "      <td>0.152679</td>\n",
       "      <td>1.214890</td>\n",
       "      <td>1.333084</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.173773</td>\n",
       "      <td>18</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>0.447277</td>\n",
       "      <td>2288.85714</td>\n",
       "      <td>133351912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>21310.5977</td>\n",
       "      <td>19418.8184</td>\n",
       "      <td>21458.9082</td>\n",
       "      <td>19298.3164</td>\n",
       "      <td>4.440000e+10</td>\n",
       "      <td>367.395508</td>\n",
       "      <td>174.899994</td>\n",
       "      <td>1.129382</td>\n",
       "      <td>0.152945</td>\n",
       "      <td>1.215430</td>\n",
       "      <td>1.344447</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.341491</td>\n",
       "      <td>11</td>\n",
       "      <td>0.127344</td>\n",
       "      <td>0.480809</td>\n",
       "      <td>2204.31469</td>\n",
       "      <td>132323572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>22805.1621</td>\n",
       "      <td>21308.3516</td>\n",
       "      <td>23642.6602</td>\n",
       "      <td>21234.6758</td>\n",
       "      <td>7.140000e+10</td>\n",
       "      <td>369.449982</td>\n",
       "      <td>176.740006</td>\n",
       "      <td>1.129446</td>\n",
       "      <td>0.153109</td>\n",
       "      <td>1.219959</td>\n",
       "      <td>1.350293</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>0.197572</td>\n",
       "      <td>10</td>\n",
       "      <td>0.135945</td>\n",
       "      <td>0.539729</td>\n",
       "      <td>2399.07752</td>\n",
       "      <td>132373209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>23137.9609</td>\n",
       "      <td>22806.7969</td>\n",
       "      <td>23238.6016</td>\n",
       "      <td>22399.8125</td>\n",
       "      <td>4.040000e+10</td>\n",
       "      <td>367.974793</td>\n",
       "      <td>176.440002</td>\n",
       "      <td>1.130301</td>\n",
       "      <td>0.153090</td>\n",
       "      <td>1.226272</td>\n",
       "      <td>1.357018</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.315601</td>\n",
       "      <td>2</td>\n",
       "      <td>0.135441</td>\n",
       "      <td>0.449503</td>\n",
       "      <td>2392.03185</td>\n",
       "      <td>131791042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Adj_Close_BTC-USD  Open_BTC-USD  High_BTC-USD  Low_BTC-USD  \\\n",
       "0 2020-12-14         19246.6445    19144.4922    19305.0996   19012.7090   \n",
       "1 2020-12-15         19417.0762    19246.9199    19525.0078   19079.8418   \n",
       "2 2020-12-16         21310.5977    19418.8184    21458.9082   19298.3164   \n",
       "3 2020-12-17         22805.1621    21308.3516    23642.6602   21234.6758   \n",
       "4 2020-12-18         23137.9609    22806.7969    23238.6016   22399.8125   \n",
       "\n",
       "   Volume_BTC-USD  Adj_Close_SPY  Adj_Close_GLD  Adj_Close_CHFUSD=X  \\\n",
       "0    2.250000e+10     361.926788     171.539993            1.125442   \n",
       "1    2.670000e+10     366.819824     173.940002            1.127930   \n",
       "2    4.440000e+10     367.395508     174.899994            1.129382   \n",
       "3    7.140000e+10     369.449982     176.740006            1.129446   \n",
       "4    4.040000e+10     367.974793     176.440002            1.130301   \n",
       "\n",
       "   Adj_Close_CNYUSD=X  Adj_Close_EURUSD=X  Adj_Close_GBPUSD=X  \\\n",
       "0            0.152772            1.213340            1.331824   \n",
       "1            0.152679            1.214890            1.333084   \n",
       "2            0.152945            1.215430            1.344447   \n",
       "3            0.153109            1.219959            1.350293   \n",
       "4            0.153090            1.226272            1.357018   \n",
       "\n",
       "   Adj_Close_JPYUSD=X  coindesk_sentiment  num_of_coindesk_posts  \\\n",
       "0            0.009621            0.249489                     12   \n",
       "1            0.009614            0.173773                     18   \n",
       "2            0.009649            0.341491                     11   \n",
       "3            0.009664            0.197572                     10   \n",
       "4            0.009696            0.315601                      2   \n",
       "\n",
       "   reddit_comments_sentiments  top_50_reddit_posts_sentiments  \\\n",
       "0                    0.158060                        0.677618   \n",
       "1                    0.101930                        0.447277   \n",
       "2                    0.127344                        0.480809   \n",
       "3                    0.135945                        0.539729   \n",
       "4                    0.135441                        0.449503   \n",
       "\n",
       "   blockchain_transactions_per_block  blockchain_hash_rates  \n",
       "0                         2167.93103              134533588  \n",
       "1                         2288.85714              133351912  \n",
       "2                         2204.31469              132323572  \n",
       "3                         2399.07752              132373209  \n",
       "4                         2392.03185              131791042  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = os.path.join(cwd,'data','cooked_data','cooked_complete_dataset.csv')\n",
    "df = pd.read_csv(PATH)\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "df['date'] = df['date'].apply(lambda x: datetime.datetime.strptime(x, \"%d/%m/%y\"))\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format='%d/%m/%Y', infer_datetime_format=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Adj_Close_BTC-USD</th>\n",
       "      <th>Open_BTC-USD</th>\n",
       "      <th>High_BTC-USD</th>\n",
       "      <th>Low_BTC-USD</th>\n",
       "      <th>Volume_BTC-USD</th>\n",
       "      <th>Adj_Close_SPY</th>\n",
       "      <th>Adj_Close_GLD</th>\n",
       "      <th>Adj_Close_CHFUSD=X</th>\n",
       "      <th>Adj_Close_CNYUSD=X</th>\n",
       "      <th>Adj_Close_EURUSD=X</th>\n",
       "      <th>Adj_Close_GBPUSD=X</th>\n",
       "      <th>Adj_Close_JPYUSD=X</th>\n",
       "      <th>coindesk_sentiment</th>\n",
       "      <th>num_of_coindesk_posts</th>\n",
       "      <th>reddit_comments_sentiments</th>\n",
       "      <th>top_50_reddit_posts_sentiments</th>\n",
       "      <th>blockchain_transactions_per_block</th>\n",
       "      <th>blockchain_hash_rates</th>\n",
       "      <th>class_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>19246.6445</td>\n",
       "      <td>19144.4922</td>\n",
       "      <td>19305.0996</td>\n",
       "      <td>19012.7090</td>\n",
       "      <td>2.250000e+10</td>\n",
       "      <td>361.926788</td>\n",
       "      <td>171.539993</td>\n",
       "      <td>1.125442</td>\n",
       "      <td>0.152772</td>\n",
       "      <td>1.213340</td>\n",
       "      <td>1.331824</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.249489</td>\n",
       "      <td>12</td>\n",
       "      <td>0.158060</td>\n",
       "      <td>0.677618</td>\n",
       "      <td>2167.93103</td>\n",
       "      <td>134533588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>19417.0762</td>\n",
       "      <td>19246.9199</td>\n",
       "      <td>19525.0078</td>\n",
       "      <td>19079.8418</td>\n",
       "      <td>2.670000e+10</td>\n",
       "      <td>366.819824</td>\n",
       "      <td>173.940002</td>\n",
       "      <td>1.127930</td>\n",
       "      <td>0.152679</td>\n",
       "      <td>1.214890</td>\n",
       "      <td>1.333084</td>\n",
       "      <td>0.009614</td>\n",
       "      <td>0.173773</td>\n",
       "      <td>18</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>0.447277</td>\n",
       "      <td>2288.85714</td>\n",
       "      <td>133351912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>21310.5977</td>\n",
       "      <td>19418.8184</td>\n",
       "      <td>21458.9082</td>\n",
       "      <td>19298.3164</td>\n",
       "      <td>4.440000e+10</td>\n",
       "      <td>367.395508</td>\n",
       "      <td>174.899994</td>\n",
       "      <td>1.129382</td>\n",
       "      <td>0.152945</td>\n",
       "      <td>1.215430</td>\n",
       "      <td>1.344447</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.341491</td>\n",
       "      <td>11</td>\n",
       "      <td>0.127344</td>\n",
       "      <td>0.480809</td>\n",
       "      <td>2204.31469</td>\n",
       "      <td>132323572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>22805.1621</td>\n",
       "      <td>21308.3516</td>\n",
       "      <td>23642.6602</td>\n",
       "      <td>21234.6758</td>\n",
       "      <td>7.140000e+10</td>\n",
       "      <td>369.449982</td>\n",
       "      <td>176.740006</td>\n",
       "      <td>1.129446</td>\n",
       "      <td>0.153109</td>\n",
       "      <td>1.219959</td>\n",
       "      <td>1.350293</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>0.197572</td>\n",
       "      <td>10</td>\n",
       "      <td>0.135945</td>\n",
       "      <td>0.539729</td>\n",
       "      <td>2399.07752</td>\n",
       "      <td>132373209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>23137.9609</td>\n",
       "      <td>22806.7969</td>\n",
       "      <td>23238.6016</td>\n",
       "      <td>22399.8125</td>\n",
       "      <td>4.040000e+10</td>\n",
       "      <td>367.974793</td>\n",
       "      <td>176.440002</td>\n",
       "      <td>1.130301</td>\n",
       "      <td>0.153090</td>\n",
       "      <td>1.226272</td>\n",
       "      <td>1.357018</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.315601</td>\n",
       "      <td>2</td>\n",
       "      <td>0.135441</td>\n",
       "      <td>0.449503</td>\n",
       "      <td>2392.03185</td>\n",
       "      <td>131791042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Adj_Close_BTC-USD  Open_BTC-USD  High_BTC-USD  Low_BTC-USD  \\\n",
       "0 2020-12-14         19246.6445    19144.4922    19305.0996   19012.7090   \n",
       "1 2020-12-15         19417.0762    19246.9199    19525.0078   19079.8418   \n",
       "2 2020-12-16         21310.5977    19418.8184    21458.9082   19298.3164   \n",
       "3 2020-12-17         22805.1621    21308.3516    23642.6602   21234.6758   \n",
       "4 2020-12-18         23137.9609    22806.7969    23238.6016   22399.8125   \n",
       "\n",
       "   Volume_BTC-USD  Adj_Close_SPY  Adj_Close_GLD  Adj_Close_CHFUSD=X  \\\n",
       "0    2.250000e+10     361.926788     171.539993            1.125442   \n",
       "1    2.670000e+10     366.819824     173.940002            1.127930   \n",
       "2    4.440000e+10     367.395508     174.899994            1.129382   \n",
       "3    7.140000e+10     369.449982     176.740006            1.129446   \n",
       "4    4.040000e+10     367.974793     176.440002            1.130301   \n",
       "\n",
       "   Adj_Close_CNYUSD=X  Adj_Close_EURUSD=X  Adj_Close_GBPUSD=X  \\\n",
       "0            0.152772            1.213340            1.331824   \n",
       "1            0.152679            1.214890            1.333084   \n",
       "2            0.152945            1.215430            1.344447   \n",
       "3            0.153109            1.219959            1.350293   \n",
       "4            0.153090            1.226272            1.357018   \n",
       "\n",
       "   Adj_Close_JPYUSD=X  coindesk_sentiment  num_of_coindesk_posts  \\\n",
       "0            0.009621            0.249489                     12   \n",
       "1            0.009614            0.173773                     18   \n",
       "2            0.009649            0.341491                     11   \n",
       "3            0.009664            0.197572                     10   \n",
       "4            0.009696            0.315601                      2   \n",
       "\n",
       "   reddit_comments_sentiments  top_50_reddit_posts_sentiments  \\\n",
       "0                    0.158060                        0.677618   \n",
       "1                    0.101930                        0.447277   \n",
       "2                    0.127344                        0.480809   \n",
       "3                    0.135945                        0.539729   \n",
       "4                    0.135441                        0.449503   \n",
       "\n",
       "   blockchain_transactions_per_block  blockchain_hash_rates  class_y  \n",
       "0                         2167.93103              134533588        0  \n",
       "1                         2288.85714              133351912        1  \n",
       "2                         2204.31469              132323572        1  \n",
       "3                         2399.07752              132373209        1  \n",
       "4                         2392.03185              131791042        1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create binary label\n",
    "df[\"class_y\"] = df[\"Adj_Close_BTC-USD\"].shift(1).dropna()\n",
    "df[\"class_y\"] = df.apply(lambda x : 1 if x[\"class_y\"] < x[\"Adj_Close_BTC-USD\"] else 0 , axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions for creating lags and scaling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag(data, dic):\n",
    "    cols = []\n",
    "    for key, value in dic.items():\n",
    "        for i in range(1, value+1):\n",
    "            cols.append(data[key].shift(i).rename('{}_lag{}'.format(data[key].name, i)))\n",
    "    return pd.concat([data[\"date\"],data[\"class_y\"]] + cols, axis = 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def scale_and_convert_to_tensor(Xtrain, Xtest, Ytrain, Ytest, scaleTarget = False):  \n",
    "    global scaler\n",
    "    \n",
    "    # Standardise features\n",
    "    Xtrain_standardised = scaler.fit_transform(Xtrain)\n",
    "    Xtest_standardised = scaler.transform(Xtest)\n",
    "    \n",
    "    # Standardise target\n",
    "    Ytrain_standardised = Ytrain\n",
    "    Ytest_standardised = Ytest\n",
    "    \n",
    "    if scaleTarget:    \n",
    "        Ytrain_standardised = scaler.fit_transform(np.array(Ytrain).reshape(-1, 1))\n",
    "        Ytest_standardised = scaler.transform(np.array(Ytest).reshape(-1, 1))\n",
    "    \n",
    "    ## Change to tensor\n",
    "    Xtrain_tensor = torch.from_numpy(Xtrain_standardised).float()\n",
    "    Ytrain_tensor = torch.from_numpy(np.array(Ytrain_standardised)).float()\n",
    "    Xtest_tensor = torch.from_numpy(Xtest_standardised).float()\n",
    "    Ytest_tensor = torch.from_numpy(np.array(Ytest_standardised)).float()\n",
    "        \n",
    "    return (Xtrain_tensor, Xtest_tensor, Ytrain_tensor, Ytest_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create feature lags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lags = {\"Adj_Close_BTC-USD\" : 1,\n",
    "                \"Adj_Close_SPY\" : 1,\n",
    "                \"Adj_Close_GLD\" : 1,\n",
    "                \"Adj_Close_CHFUSD=X\" : 1,\n",
    "                \"Adj_Close_EURUSD=X\" : 1,\n",
    "                \"Adj_Close_GBPUSD=X\" : 1,\n",
    "                \"Adj_Close_JPYUSD=X\" : 1,\n",
    "                \"blockchain_transactions_per_block\" : 1,\n",
    "                \"blockchain_hash_rates\" : 1}\n",
    "\n",
    "data = lag(df, feature_lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Handle train-test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data[\"date\"] >= \"2021-01-01\") & (data[\"date\"] <= \"2021-04-12\")]\n",
    "\n",
    "## train, validation and test split\n",
    "train = data[(data[\"date\"] >= \"2021-01-01\") & (data[\"date\"] <= \"2021-03-14\")]\n",
    "validation = data[(data[\"date\"] >= \"2021-03-15\") & (data[\"date\"] <= \"2021-03-29\")]\n",
    "test = data[(data[\"date\"] >= \"2021-03-30\") & (data[\"date\"] <= \"2021-04-12\")]\n",
    "\n",
    "## refit (refit = train + validation) and full for later use \n",
    "refit = data[(data[\"date\"] >= \"2021-01-01\") & (data[\"date\"] <= \"2021-03-29\")]\n",
    "full = data.copy(deep = True)\n",
    "\n",
    "## train \n",
    "X_train = train.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_train = train[\"class_y\"]\n",
    "\n",
    "## val\n",
    "X_val = validation.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_val = validation[\"class_y\"]\n",
    "\n",
    "## test\n",
    "X_test = test.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_test = test[\"class_y\"]\n",
    "\n",
    "## refit\n",
    "X_refit = refit.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_refit = refit[\"class_y\"]\n",
    "\n",
    "## full\n",
    "X_full = full.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_full = full[\"class_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Standardise dataset and transform into tensors for pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train tensor torch.Size([73, 9])\n",
      "Y train tensor torch.Size([73])\n",
      "X val tensor torch.Size([15, 9])\n",
      "Y val tensor torch.Size([15])\n",
      "X test tensor torch.Size([14, 9])\n",
      "Y test tensor torch.Size([14])\n"
     ]
    }
   ],
   "source": [
    "## Standardise datasets and convert into tensors\n",
    "Xtrain_tensor, Xval_tensor, Ytrain_tensor, Yval_tensor = scale_and_convert_to_tensor(X_train, X_val, y_train, y_val)\n",
    "_, Xtest_tensor, _, Ytest_tensor = scale_and_convert_to_tensor(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"X train tensor\",Xtrain_tensor.shape)\n",
    "print(\"Y train tensor\",Ytrain_tensor.shape)\n",
    "\n",
    "print(\"X val tensor\",Xval_tensor.shape)\n",
    "print(\"Y val tensor\",Yval_tensor.shape)\n",
    "\n",
    "print(\"X test tensor\",Xtest_tensor.shape)\n",
    "print(\"Y test tensor\",Ytest_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Define BNN training and evaluation pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_evaluate_classification(Xtrain_tensor, Ytrain_tensor, Xtest_tensor, Ytest_tensor ,\n",
    "                                            layers = [100,20], learning_param = 0.01, kl_weight = 0.01, steps = 100, threshold = 0.50, printStep = True):    \n",
    "    in_features = Xtrain_tensor.shape[1]\n",
    "    batch_size = Xtrain_tensor.shape[0]\n",
    "    \n",
    "    ## Ensure reproducibility\n",
    "    seed = 1\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Build model\n",
    "    layer = []\n",
    "    \n",
    "    ## Input layer\n",
    "    layer.append(bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features = in_features, out_features = layers[0]))\n",
    "    layer.append(nn.ReLU())\n",
    "    \n",
    "    ## Hidden layers\n",
    "    for index, neurons in enumerate(layers):\n",
    "        if index != (len(layers)-1):\n",
    "            layer.append(bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=neurons, out_features=layers[index+1]))\n",
    "            layer.append(nn.ReLU())\n",
    "\n",
    "    ## Output layer\n",
    "    layer.append(bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=layers[-1], out_features=1))\n",
    "    layer.append(nn.Sigmoid())\n",
    "    \n",
    "    model = nn.Sequential(*layer)\n",
    "    \n",
    "    ### Define Loss - CrossEntropy for classification\n",
    "    cross_entropy_loss = nn.BCELoss()\n",
    "    kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "\n",
    "    ## Define optimiser with learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_param)\n",
    "    \n",
    "    ### Train model\n",
    "    for step in range(steps):\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        pre = model(Xtrain_tensor)\n",
    "        cross_entropy = cross_entropy_loss(pre, Ytrain_tensor.reshape(-1, 1).type(torch.FloatTensor))\n",
    "        kl = kl_loss(model)\n",
    "        total_cost = cross_entropy + kl_weight*kl\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_cost.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if step%20==0 and printStep:\n",
    "            print('[Step %d]: CE : %.8f, KL : %.8f' % (step , cross_entropy.item(), kl.item()))\n",
    "\n",
    "    train_cross_entropy = cross_entropy.item()\n",
    "    kl_loss = kl.item()\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    ## Performance Evaluation on train\n",
    "    y_predict_train = model(Xtrain_tensor)\n",
    "    y_predict_binary_train = pd.Series(y_predict_train.detach().numpy().flatten()).apply(lambda x: 1 if x >= threshold else 0)\n",
    "    train_accuracy = accuracy_score(Ytrain_tensor.detach().numpy(), y_predict_binary_train)\n",
    "    \n",
    "    ## Performance Evaluation on test\n",
    "    y_predict = model(Xtest_tensor)\n",
    "    y_predict_binary = pd.Series(y_predict.detach().numpy().flatten()).apply(lambda x: 1 if x >= threshold else 0)\n",
    "    test_cross_entropy = cross_entropy_loss(y_predict, Ytest_tensor.reshape(-1, 1).type(torch.FloatTensor)).item()\n",
    "    test_accuracy = accuracy_score(Ytest_tensor.detach().numpy(), y_predict_binary)\n",
    "\n",
    "    return (y_predict_binary , train_cross_entropy, test_cross_entropy, train_accuracy, test_accuracy, kl_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Perform Grid Search**\n",
    "\n",
    "Perform grid search and evaluate based on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Layer:  [32, 16]\n",
      "-- Learning Param:  0.001\n",
      "-- Learning Param:  0.011\n",
      "-- Learning Param:  0.021\n",
      "-- Learning Param:  0.032\n",
      "-- Learning Param:  0.042\n",
      "-- Learning Param:  0.052\n",
      "-- Learning Param:  0.062\n",
      "-- Learning Param:  0.072\n",
      "-- Learning Param:  0.082\n",
      "-- Learning Param:  0.093\n",
      "-- Learning Param:  0.103\n",
      "-- Learning Param:  0.113\n",
      "-- Learning Param:  0.123\n",
      "-- Learning Param:  0.133\n",
      "-- Learning Param:  0.144\n",
      "-- Learning Param:  0.154\n",
      "-- Learning Param:  0.164\n",
      "-- Learning Param:  0.174\n",
      "-- Learning Param:  0.184\n",
      "-- Learning Param:  0.194\n",
      "-- Learning Param:  0.205\n",
      "-- Learning Param:  0.215\n",
      "-- Learning Param:  0.225\n",
      "-- Learning Param:  0.235\n",
      "-- Learning Param:  0.245\n",
      "-- Learning Param:  0.256\n",
      "-- Learning Param:  0.266\n",
      "-- Learning Param:  0.276\n",
      "-- Learning Param:  0.286\n",
      "-- Learning Param:  0.296\n",
      "-- Learning Param:  0.307\n",
      "-- Learning Param:  0.317\n",
      "-- Learning Param:  0.327\n",
      "-- Learning Param:  0.337\n",
      "-- Learning Param:  0.347\n",
      "-- Learning Param:  0.357\n",
      "-- Learning Param:  0.368\n",
      "-- Learning Param:  0.378\n",
      "-- Learning Param:  0.388\n",
      "-- Learning Param:  0.398\n",
      "-- Learning Param:  0.408\n",
      "-- Learning Param:  0.419\n",
      "-- Learning Param:  0.429\n",
      "-- Learning Param:  0.439\n",
      "-- Learning Param:  0.449\n",
      "-- Learning Param:  0.459\n",
      "-- Learning Param:  0.469\n",
      "-- Learning Param:  0.48\n",
      "-- Learning Param:  0.49\n",
      "-- Learning Param:  0.5\n",
      "--- Layer:  [32, 8]\n",
      "-- Learning Param:  0.001\n",
      "-- Learning Param:  0.011\n",
      "-- Learning Param:  0.021\n",
      "-- Learning Param:  0.032\n",
      "-- Learning Param:  0.042\n",
      "-- Learning Param:  0.052\n",
      "-- Learning Param:  0.062\n",
      "-- Learning Param:  0.072\n",
      "-- Learning Param:  0.082\n",
      "-- Learning Param:  0.093\n",
      "-- Learning Param:  0.103\n",
      "-- Learning Param:  0.113\n",
      "-- Learning Param:  0.123\n",
      "-- Learning Param:  0.133\n",
      "-- Learning Param:  0.144\n",
      "-- Learning Param:  0.154\n",
      "-- Learning Param:  0.164\n",
      "-- Learning Param:  0.174\n",
      "-- Learning Param:  0.184\n",
      "-- Learning Param:  0.194\n",
      "-- Learning Param:  0.205\n",
      "-- Learning Param:  0.215\n",
      "-- Learning Param:  0.225\n",
      "-- Learning Param:  0.235\n",
      "-- Learning Param:  0.245\n",
      "-- Learning Param:  0.256\n",
      "-- Learning Param:  0.266\n",
      "-- Learning Param:  0.276\n",
      "-- Learning Param:  0.286\n",
      "-- Learning Param:  0.296\n",
      "-- Learning Param:  0.307\n",
      "-- Learning Param:  0.317\n",
      "-- Learning Param:  0.327\n",
      "-- Learning Param:  0.337\n",
      "-- Learning Param:  0.347\n",
      "-- Learning Param:  0.357\n",
      "-- Learning Param:  0.368\n",
      "-- Learning Param:  0.378\n",
      "-- Learning Param:  0.388\n",
      "-- Learning Param:  0.398\n",
      "-- Learning Param:  0.408\n",
      "-- Learning Param:  0.419\n",
      "-- Learning Param:  0.429\n",
      "-- Learning Param:  0.439\n",
      "-- Learning Param:  0.449\n",
      "-- Learning Param:  0.459\n",
      "-- Learning Param:  0.469\n",
      "-- Learning Param:  0.48\n",
      "-- Learning Param:  0.49\n",
      "-- Learning Param:  0.5\n",
      "--- Layer:  [32, 16, 8]\n",
      "-- Learning Param:  0.001\n",
      "-- Learning Param:  0.011\n",
      "-- Learning Param:  0.021\n",
      "-- Learning Param:  0.032\n",
      "-- Learning Param:  0.042\n",
      "-- Learning Param:  0.052\n",
      "-- Learning Param:  0.062\n",
      "-- Learning Param:  0.072\n",
      "-- Learning Param:  0.082\n",
      "-- Learning Param:  0.093\n",
      "-- Learning Param:  0.103\n",
      "-- Learning Param:  0.113\n",
      "-- Learning Param:  0.123\n",
      "-- Learning Param:  0.133\n",
      "-- Learning Param:  0.144\n",
      "-- Learning Param:  0.154\n",
      "-- Learning Param:  0.164\n",
      "-- Learning Param:  0.174\n",
      "-- Learning Param:  0.184\n",
      "-- Learning Param:  0.194\n",
      "-- Learning Param:  0.205\n",
      "-- Learning Param:  0.215\n",
      "-- Learning Param:  0.225\n",
      "-- Learning Param:  0.235\n",
      "-- Learning Param:  0.245\n",
      "-- Learning Param:  0.256\n",
      "-- Learning Param:  0.266\n",
      "-- Learning Param:  0.276\n",
      "-- Learning Param:  0.286\n",
      "-- Learning Param:  0.296\n",
      "-- Learning Param:  0.307\n",
      "-- Learning Param:  0.317\n",
      "-- Learning Param:  0.327\n",
      "-- Learning Param:  0.337\n",
      "-- Learning Param:  0.347\n",
      "-- Learning Param:  0.357\n",
      "-- Learning Param:  0.368\n",
      "-- Learning Param:  0.378\n",
      "-- Learning Param:  0.388\n",
      "-- Learning Param:  0.398\n",
      "-- Learning Param:  0.408\n",
      "-- Learning Param:  0.419\n",
      "-- Learning Param:  0.429\n",
      "-- Learning Param:  0.439\n",
      "-- Learning Param:  0.449\n",
      "-- Learning Param:  0.459\n",
      "-- Learning Param:  0.469\n",
      "-- Learning Param:  0.48\n",
      "-- Learning Param:  0.49\n",
      "-- Learning Param:  0.5\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameter Tuning --> find best parameters\n",
    "train_accuracy_list = []\n",
    "val_accuracy_list = []\n",
    "combination = []\n",
    "\n",
    "learning_param_list = pd.Series(np.linspace(0.001,0.5,50)).apply(lambda x: round(x,3))\n",
    "kl_weight =  pd.Series(np.linspace(0.001,0.5,50)).apply(lambda x: round(x,3))\n",
    "layers_list = ([32,16],[32,8],[32,16,8])\n",
    "\n",
    "for layer in layers_list:\n",
    "    print(\"--- Layer: \", layer)\n",
    "    for lr in learning_param_list:\n",
    "        print(\"-- Learning Param: \", lr)\n",
    "        for kl in kl_weight:\n",
    "            combination.append(\"layer: {} lr: {} kl: {}\".format(layer,lr,kl))\n",
    "            _ , _, _, train_accuracy, val_accuracy, _ = train_model_and_evaluate_classification(Xtrain_tensor, Ytrain_tensor, Xval_tensor, Yval_tensor, layer, learning_param = lr, kl_weight = kl, steps = 100, printStep = False)\n",
    "            train_accuracy_list.append(train_accuracy)\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "            \n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Val Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>layer: [32, 16] lr: 0.052 kl: 0.082</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>layer: [32, 16] lr: 0.093 kl: 0.021</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>layer: [32, 16] lr: 0.123 kl: 0.123</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>layer: [32, 16] lr: 0.154 kl: 0.042</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>layer: [32, 16] lr: 0.164 kl: 0.052</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Combination  Train Accuracy  Val Accuracy\n",
       "258  layer: [32, 16] lr: 0.052 kl: 0.082        0.643836      0.733333\n",
       "452  layer: [32, 16] lr: 0.093 kl: 0.021        0.753425      0.733333\n",
       "612  layer: [32, 16] lr: 0.123 kl: 0.123        0.657534      0.733333\n",
       "754  layer: [32, 16] lr: 0.154 kl: 0.042        0.602740      0.733333\n",
       "805  layer: [32, 16] lr: 0.164 kl: 0.052        0.547945      0.733333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Combination\": combination,\"Train Accuracy\":train_accuracy_list, \"Val Accuracy\":val_accuracy_list})\n",
    "results.to_csv(\"Combinations_classification_withoutSentiments&lagged2.csv\")\n",
    "\n",
    "## Find the hyperparameters with gives the highest val accuracy\n",
    "results[results['Val Accuracy'] ==  results['Val Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7534246575342466\n",
      "Val Accuracy:  0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "layer = [32, 16]\n",
    "lr = 0.093\n",
    "kl = 0.021\n",
    "\n",
    "_ , _, _, train_accuracy, val_accuracy, _ = train_model_and_evaluate_classification(Xtrain_tensor, Ytrain_tensor, Xval_tensor, Yval_tensor, layers = layer, learning_param = lr, kl_weight = kl, steps = 100, printStep = False)\n",
    "print(\"Train Accuracy: \",train_accuracy)\n",
    "print(\"Val Accuracy: \",val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Retrain the model with selected hyperparameters and all train data available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function for retraining the model with all data available\n",
    "def train_model(Xtrain_tensor, Ytrain_tensor, layers = [100,20], learning_param = 0.01, kl_weight = 0.01, steps = 100, threshold = 0.50):    \n",
    "    \"\"\" \n",
    "    Trains model and returns predictions on entire dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    in_features = Xtrain_tensor.shape[1]\n",
    "    batch_size = Xtrain_tensor.shape[0]\n",
    "    \n",
    "    ## Ensure reproducibility\n",
    "    seed = 1\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Build model\n",
    "    layer = []\n",
    "    \n",
    "    ## Input layer\n",
    "    layer.append(bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features = in_features, out_features = layers[0]))\n",
    "    layer.append(nn.ReLU())\n",
    "    \n",
    "    ## Hidden layers\n",
    "    for index, neurons in enumerate(layers):\n",
    "        if index != (len(layers)-1):\n",
    "            layer.append(bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=neurons, out_features=layers[index+1]))\n",
    "            layer.append(nn.ReLU())\n",
    "\n",
    "    ## Output layer\n",
    "    layer.append(bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=layers[-1], out_features=1))\n",
    "    layer.append(nn.Sigmoid())\n",
    "    \n",
    "    model = nn.Sequential(*layer)\n",
    "    \n",
    "    ## Print Model\n",
    "    #print(summary(model,(batch_size,in_features)))\n",
    "    #print(model)\n",
    "    \n",
    "    ### Define Loss - CrossEntropy for classification\n",
    "    cross_entropy_loss = nn.BCELoss()\n",
    "    kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "\n",
    "    ## Define optimiser with learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_param)\n",
    "    \n",
    "    ### Train model\n",
    "    for step in range(steps):\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        pre = model(Xtrain_tensor)\n",
    "        cross_entropy = cross_entropy_loss(pre, Ytrain_tensor.reshape(-1, 1).type(torch.FloatTensor))\n",
    "        kl = kl_loss(model)\n",
    "        total_cost = cross_entropy + kl_weight*kl\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    pre_binary = pd.Series(pre.detach().numpy().flatten()).apply(lambda x: 1 if x >= threshold else 0)\n",
    "    \n",
    "    return (model, pre_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X refit tensor torch.Size([88, 9])\n",
      "Y refit tensor torch.Size([88])\n"
     ]
    }
   ],
   "source": [
    "### Standardise refit data (train + val)\n",
    "Xrefit_tensor, _, Yrefit_tensor, _ = scale_and_convert_to_tensor(X_refit, X_refit, y_refit, y_refit)\n",
    "print(\"X refit tensor\",Xrefit_tensor.shape)\n",
    "print(\"Y refit tensor\",Yrefit_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6818181818181818\n",
      "Test Accuracy:  0.5714285714285714\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     0\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    0\n",
      "13    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Train on refit data and evaluate on test\n",
    "y_predict_binary , _, _, train_accuracy, test_accuracy, _ = train_model_and_evaluate_classification(Xrefit_tensor, Yrefit_tensor, Xtest_tensor, Ytest_tensor, layer, learning_param = lr, kl_weight = kl, steps = 100, printStep = False)\n",
    "print(\"Train Accuracy: \",train_accuracy)\n",
    "print(\"Test Accuracy: \",test_accuracy)\n",
    "print(y_predict_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Obtain predictions for Backtesting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X test tensor torch.Size([102, 9])\n",
      "Y test tensor torch.Size([102])\n"
     ]
    }
   ],
   "source": [
    "### Standardise full data \n",
    "Xfull_tensor, _, Yfull_tensor, _ = scale_and_convert_to_tensor(X_full, X_full, y_full, y_full)\n",
    "print(\"X test tensor\",Xfull_tensor.shape)\n",
    "print(\"Y test tensor\",Yfull_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, pre_binary = train_model(Xfull_tensor, Yfull_tensor, layers = layer, learning_param = lr, kl_weight = kl, steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176470588235294"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_full, pre_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(pre_binary).to_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create Lags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lags = {\"Adj_Close_BTC-USD\" : 1, \n",
    "                \"Adj_Close_SPY\" : 1,\n",
    "                \"Adj_Close_GLD\" : 1,\n",
    "                \"Adj_Close_CHFUSD=X\" : 1,\n",
    "                \"Adj_Close_EURUSD=X\" : 1,\n",
    "                \"Adj_Close_GBPUSD=X\" : 1,\n",
    "                \"Adj_Close_JPYUSD=X\" : 1,\n",
    "                \"blockchain_transactions_per_block\" : 1,\n",
    "                \"blockchain_hash_rates\" : 1,\n",
    "                \"coindesk_sentiment\" : 1,\n",
    "                \"reddit_comments_sentiments\" : 1,\n",
    "                \"top_50_reddit_posts_sentiments\" : 1}\n",
    "\n",
    "\n",
    "data = lag(df, feature_lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Handle Train-test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data[\"date\"] >= \"2021-01-01\") & (data[\"date\"] <= \"2021-04-12\")]\n",
    "\n",
    "## train, validation and test split\n",
    "train = data[(data[\"date\"] >= \"2021-01-01\") & (data[\"date\"] <= \"2021-03-14\")]\n",
    "validation = data[(data[\"date\"] >= \"2021-03-15\") & (data[\"date\"] <= \"2021-03-29\")]\n",
    "test = data[(data[\"date\"] >= \"2021-03-30\") & (data[\"date\"] <= \"2021-04-12\")]\n",
    "\n",
    "## refit (refit = train + validation) and full for later use \n",
    "refit = data[(data[\"date\"] >= \"2021-01-01\") & (data[\"date\"] <= \"2021-03-29\")]\n",
    "full = data.copy(deep = True)\n",
    "\n",
    "## train \n",
    "X_train = train.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_train = train[\"class_y\"]\n",
    "\n",
    "## val\n",
    "X_val = validation.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_val = validation[\"class_y\"]\n",
    "\n",
    "## test\n",
    "X_test = test.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_test = test[\"class_y\"]\n",
    "\n",
    "## refit\n",
    "X_refit = refit.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_refit = refit[\"class_y\"]\n",
    "\n",
    "## full\n",
    "X_full = full.drop([\"date\", \"class_y\"], axis = 1)\n",
    "y_full = full[\"class_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Standardise dataset and transform to tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train tensor torch.Size([73, 12])\n",
      "Y train tensor torch.Size([73])\n",
      "X val tensor torch.Size([15, 12])\n",
      "Y val tensor torch.Size([15])\n",
      "X test tensor torch.Size([14, 12])\n",
      "Y test tensor torch.Size([14])\n"
     ]
    }
   ],
   "source": [
    "## Standardise datasets and convert into tensors\n",
    "Xtrain_tensor, Xval_tensor, Ytrain_tensor, Yval_tensor = scale_and_convert_to_tensor(X_train, X_val, y_train, y_val)\n",
    "_, Xtest_tensor, _, Ytest_tensor = scale_and_convert_to_tensor(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"X train tensor\",Xtrain_tensor.shape)\n",
    "print(\"Y train tensor\",Ytrain_tensor.shape)\n",
    "\n",
    "print(\"X val tensor\",Xval_tensor.shape)\n",
    "print(\"Y val tensor\",Yval_tensor.shape)\n",
    "\n",
    "print(\"X test tensor\",Xtest_tensor.shape)\n",
    "print(\"Y test tensor\",Ytest_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Perform Gridsearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Layer:  [32, 16]\n",
      "-- Learning Param:  0.001\n",
      "-- Learning Param:  0.011\n",
      "-- Learning Param:  0.021\n",
      "-- Learning Param:  0.032\n",
      "-- Learning Param:  0.042\n",
      "-- Learning Param:  0.052\n",
      "-- Learning Param:  0.062\n",
      "-- Learning Param:  0.072\n",
      "-- Learning Param:  0.082\n",
      "-- Learning Param:  0.093\n",
      "-- Learning Param:  0.103\n",
      "-- Learning Param:  0.113\n",
      "-- Learning Param:  0.123\n",
      "-- Learning Param:  0.133\n",
      "-- Learning Param:  0.144\n",
      "-- Learning Param:  0.154\n",
      "-- Learning Param:  0.164\n",
      "-- Learning Param:  0.174\n",
      "-- Learning Param:  0.184\n",
      "-- Learning Param:  0.194\n",
      "-- Learning Param:  0.205\n",
      "-- Learning Param:  0.215\n",
      "-- Learning Param:  0.225\n",
      "-- Learning Param:  0.235\n",
      "-- Learning Param:  0.245\n",
      "-- Learning Param:  0.256\n",
      "-- Learning Param:  0.266\n",
      "-- Learning Param:  0.276\n",
      "-- Learning Param:  0.286\n",
      "-- Learning Param:  0.296\n",
      "-- Learning Param:  0.307\n",
      "-- Learning Param:  0.317\n",
      "-- Learning Param:  0.327\n",
      "-- Learning Param:  0.337\n",
      "-- Learning Param:  0.347\n",
      "-- Learning Param:  0.357\n",
      "-- Learning Param:  0.368\n",
      "-- Learning Param:  0.378\n",
      "-- Learning Param:  0.388\n",
      "-- Learning Param:  0.398\n",
      "-- Learning Param:  0.408\n",
      "-- Learning Param:  0.419\n",
      "-- Learning Param:  0.429\n",
      "-- Learning Param:  0.439\n",
      "-- Learning Param:  0.449\n",
      "-- Learning Param:  0.459\n",
      "-- Learning Param:  0.469\n",
      "-- Learning Param:  0.48\n",
      "-- Learning Param:  0.49\n",
      "-- Learning Param:  0.5\n",
      "--- Layer:  [32, 8]\n",
      "-- Learning Param:  0.001\n",
      "-- Learning Param:  0.011\n",
      "-- Learning Param:  0.021\n",
      "-- Learning Param:  0.032\n",
      "-- Learning Param:  0.042\n",
      "-- Learning Param:  0.052\n",
      "-- Learning Param:  0.062\n",
      "-- Learning Param:  0.072\n",
      "-- Learning Param:  0.082\n",
      "-- Learning Param:  0.093\n",
      "-- Learning Param:  0.103\n",
      "-- Learning Param:  0.113\n",
      "-- Learning Param:  0.123\n",
      "-- Learning Param:  0.133\n",
      "-- Learning Param:  0.144\n",
      "-- Learning Param:  0.154\n",
      "-- Learning Param:  0.164\n",
      "-- Learning Param:  0.174\n",
      "-- Learning Param:  0.184\n",
      "-- Learning Param:  0.194\n",
      "-- Learning Param:  0.205\n",
      "-- Learning Param:  0.215\n",
      "-- Learning Param:  0.225\n",
      "-- Learning Param:  0.235\n",
      "-- Learning Param:  0.245\n",
      "-- Learning Param:  0.256\n",
      "-- Learning Param:  0.266\n",
      "-- Learning Param:  0.276\n",
      "-- Learning Param:  0.286\n",
      "-- Learning Param:  0.296\n",
      "-- Learning Param:  0.307\n",
      "-- Learning Param:  0.317\n",
      "-- Learning Param:  0.327\n",
      "-- Learning Param:  0.337\n",
      "-- Learning Param:  0.347\n",
      "-- Learning Param:  0.357\n",
      "-- Learning Param:  0.368\n",
      "-- Learning Param:  0.378\n",
      "-- Learning Param:  0.388\n",
      "-- Learning Param:  0.398\n",
      "-- Learning Param:  0.408\n",
      "-- Learning Param:  0.419\n",
      "-- Learning Param:  0.429\n",
      "-- Learning Param:  0.439\n",
      "-- Learning Param:  0.449\n",
      "-- Learning Param:  0.459\n",
      "-- Learning Param:  0.469\n",
      "-- Learning Param:  0.48\n",
      "-- Learning Param:  0.49\n",
      "-- Learning Param:  0.5\n",
      "--- Layer:  [32, 16, 8]\n",
      "-- Learning Param:  0.001\n",
      "-- Learning Param:  0.011\n",
      "-- Learning Param:  0.021\n",
      "-- Learning Param:  0.032\n",
      "-- Learning Param:  0.042\n",
      "-- Learning Param:  0.052\n",
      "-- Learning Param:  0.062\n",
      "-- Learning Param:  0.072\n",
      "-- Learning Param:  0.082\n",
      "-- Learning Param:  0.093\n",
      "-- Learning Param:  0.103\n",
      "-- Learning Param:  0.113\n",
      "-- Learning Param:  0.123\n",
      "-- Learning Param:  0.133\n",
      "-- Learning Param:  0.144\n",
      "-- Learning Param:  0.154\n",
      "-- Learning Param:  0.164\n",
      "-- Learning Param:  0.174\n",
      "-- Learning Param:  0.184\n",
      "-- Learning Param:  0.194\n",
      "-- Learning Param:  0.205\n",
      "-- Learning Param:  0.215\n",
      "-- Learning Param:  0.225\n",
      "-- Learning Param:  0.235\n",
      "-- Learning Param:  0.245\n",
      "-- Learning Param:  0.256\n",
      "-- Learning Param:  0.266\n",
      "-- Learning Param:  0.276\n",
      "-- Learning Param:  0.286\n",
      "-- Learning Param:  0.296\n",
      "-- Learning Param:  0.307\n",
      "-- Learning Param:  0.317\n",
      "-- Learning Param:  0.327\n",
      "-- Learning Param:  0.337\n",
      "-- Learning Param:  0.347\n",
      "-- Learning Param:  0.357\n",
      "-- Learning Param:  0.368\n",
      "-- Learning Param:  0.378\n",
      "-- Learning Param:  0.388\n",
      "-- Learning Param:  0.398\n",
      "-- Learning Param:  0.408\n",
      "-- Learning Param:  0.419\n",
      "-- Learning Param:  0.429\n",
      "-- Learning Param:  0.439\n",
      "-- Learning Param:  0.449\n",
      "-- Learning Param:  0.459\n",
      "-- Learning Param:  0.469\n",
      "-- Learning Param:  0.48\n",
      "-- Learning Param:  0.49\n",
      "-- Learning Param:  0.5\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameter Tuning --> find best parameters\n",
    "train_accuracy_list = []\n",
    "val_accuracy_list = []\n",
    "combination = []\n",
    "\n",
    "learning_param_list = pd.Series(np.linspace(0.001,0.5,50)).apply(lambda x: round(x,3))\n",
    "kl_weight =  pd.Series(np.linspace(0.001,0.5,50)).apply(lambda x: round(x,3))\n",
    "layers_list = ([32,16],[32,8],[32,16,8])\n",
    "\n",
    "for layer in layers_list:\n",
    "    print(\"--- Layer: \", layer)\n",
    "    for lr in learning_param_list:\n",
    "        print(\"-- Learning Param: \", lr)\n",
    "        for kl in kl_weight:\n",
    "            combination.append(\"layer: {} lr: {} kl: {}\".format(layer,lr,kl))\n",
    "            _ , _, _, train_accuracy, val_accuracy, _ = train_model_and_evaluate_classification(Xtrain_tensor, Ytrain_tensor, Xval_tensor, Yval_tensor, layer, learning_param = lr, kl_weight = kl, steps = 100, printStep = False)\n",
    "            train_accuracy_list.append(train_accuracy)\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "            \n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combination</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Val Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>layer: [32, 8] lr: 0.042 kl: 0.052</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>layer: [32, 8] lr: 0.225 kl: 0.398</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Combination  Train Accuracy  Val Accuracy\n",
       "2705  layer: [32, 8] lr: 0.042 kl: 0.052        0.917808      0.866667\n",
       "3639  layer: [32, 8] lr: 0.225 kl: 0.398        0.547945      0.866667"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Combination\": combination,\"Train Accuracy\":train_accuracy_list, \"Val Accuracy\":val_accuracy_list})\n",
    "results.to_csv(\"Combinations_classification_withSentiments&lagged2.csv\")\n",
    "\n",
    "## Find the hyperparameters with gives the highest val and train accuracy\n",
    "results[results['Val Accuracy'] ==  results['Val Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9178082191780822\n",
      "Val Accuracy:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "layer = [32, 8]\n",
    "lr = 0.042\n",
    "kl =0.052\n",
    "\n",
    "_ , _, _, train_accuracy, val_accuracy, _ = train_model_and_evaluate_classification(Xtrain_tensor, Ytrain_tensor, Xval_tensor, Yval_tensor, layer, learning_param = lr, kl_weight = kl, steps = 100, printStep = False)\n",
    "print(\"Train Accuracy: \",train_accuracy)\n",
    "print(\"Val Accuracy: \",val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Retrain the model with selected hyperparameters and all data available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X refit tensor torch.Size([88, 12])\n",
      "Y refit tensor torch.Size([88])\n"
     ]
    }
   ],
   "source": [
    "### Standardise refit data (train + val)\n",
    "Xrefit_tensor, _, Yrefit_tensor, _ = scale_and_convert_to_tensor(X_refit, X_refit, y_refit, y_refit)\n",
    "\n",
    "print(\"X refit tensor\",Xrefit_tensor.shape)\n",
    "print(\"Y refit tensor\",Yrefit_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8977272727272727\n",
      "Test Accuracy:  0.6428571428571429\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Train on refit data and evaluate on test\n",
    "y_predict_binary , _, _, train_accuracy, test_accuracy, _ = train_model_and_evaluate_classification(Xrefit_tensor, Yrefit_tensor, Xtest_tensor, Ytest_tensor, layer, learning_param = lr, kl_weight = kl, steps = 100, printStep = False)\n",
    "print(\"Train Accuracy: \",train_accuracy)\n",
    "print(\"Test Accuracy: \",test_accuracy)\n",
    "print(y_predict_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Obtain predictions for Backtesting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X test tensor torch.Size([102, 12])\n",
      "Y test tensor torch.Size([102])\n"
     ]
    }
   ],
   "source": [
    "### Standardise full data \n",
    "Xfull_tensor, _, Yfull_tensor, _ = scale_and_convert_to_tensor(X_full, X_full, y_full, y_full)\n",
    "print(\"X test tensor\",Xfull_tensor.shape)\n",
    "print(\"Y test tensor\",Yfull_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8823529411764706"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, pre_binary = train_model(Xfull_tensor, Yfull_tensor, layers = layer, learning_param = lr, kl_weight = kl, steps = 100)\n",
    "accuracy_score(y_full, pre_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(pre_binary).to_csv(\"out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
